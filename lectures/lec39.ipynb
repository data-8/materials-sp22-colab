{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "\n",
    "!mkdir -p '/content/gdrive/My Drive/colab-materials-data8-notebooks/'\n",
    "!git clone https://github.com/data-8/materials-sp22-colab '/content/gdrive/My Drive/colab-materials-data8-notebooks/materials-sp22-colab/'\n",
    "\n",
    "%cd /content/gdrive/MyDrive/colab-materials-data8-notebooks/materials-sp22-colab/lectures/",
    "\n",
    "from datascience import *\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = Table.read_table(\"scores.csv\")\n",
    "scores.drop(2).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt1 = scores.column('Midterm 1')\n",
    "mt2 = scores.column('Midterm 2')\n",
    "print('Midterm 1 avg:', np.average(mt1), 'std dev:', np.std(mt1))\n",
    "print('Midterm 2 avg:', np.average(mt2), 'std dev:', np.std(mt2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Scale Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt1_actual = 21\n",
    "mt2_estimate_1 = mt1_actual / 40 * 50\n",
    "mt2_estimate_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt2_estimate_1 - np.average(mt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mt2_estimate_1 - np.average(mt2)) / np.std(mt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mt1_actual - np.average(mt1)) / np.std(mt1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt1_actual = 21\n",
    "mt1_z = (mt1_actual - np.average(mt1)) / np.std(mt1)\n",
    "mt2_estimate_2 = np.average(mt2) + mt1_z * np.std(mt2)\n",
    "mt2_estimate_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt2_estimate_2 - np.average(mt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mt2_estimate_2 - np.average(mt2)) / np.std(mt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.hist('Midterm 1', unit='point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.hist('Midterm 2', unit='point')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3: Percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt1_actual = 21\n",
    "mt1_percentile = sum(mt1 <= mt1_actual) / len(mt1) * 100\n",
    "mt1_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile(mt1_percentile, mt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile(mt1_percentile, mt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.where('Midterm 1', 21).hist('Midterm 2', normed=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 4: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_units(arr):\n",
    "    \"\"\"Converts an array to standard units \"\"\"\n",
    "    return (arr - np.average(arr))/np.std(arr)\n",
    "\n",
    "def correlation(t, x, y):\n",
    "    \"\"\"Computes correlation: t is a table, and x and y are column names \"\"\"\n",
    "    x_standard = standard_units(t.column(x))\n",
    "    y_standard = standard_units(t.column(y))\n",
    "    return np.average(x_standard * y_standard)\n",
    "\n",
    "def slope(t, x, y):\n",
    "    \"\"\"Computes the slope of the regression line, like correlation above \"\"\"\n",
    "    r = correlation(t, x, y)\n",
    "    y_sd = np.std(t.column(y))\n",
    "    x_sd = np.std(t.column(x))\n",
    "    return r * y_sd / x_sd\n",
    "\n",
    "def intercept(t, x, y):\n",
    "    \"\"\"Computes the intercept of the regression line, like slope above \"\"\"\n",
    "    x_mean = np.mean(t.column(x))\n",
    "    y_mean = np.mean(t.column(y))\n",
    "    return y_mean - slope(t, x, y)*x_mean\n",
    "\n",
    "def fitted_values(t, x, y):\n",
    "    \"\"\"Return an array of the regression estimates (predictions) at all the x values\"\"\"\n",
    "    a = slope(t, x, y)\n",
    "    b = intercept(t, x, y)\n",
    "    return a*t.column(x) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = correlation(scores, 'Midterm 1', 'Midterm 2')\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt1_actual = 21\n",
    "mt1_z = (mt1_actual - np.average(mt1)) / np.std(mt1)\n",
    "mt2_estimate_2 = np.average(mt2) + mt1_z * r * np.std(mt2)\n",
    "mt2_estimate_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.scatter('Midterm 1', 'Midterm 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = slope(scores, 'Midterm 1', 'Midterm 2')\n",
    "b = intercept(scores, 'Midterm 1', 'Midterm 2')\n",
    "scores.drop(2).with_column('Fitted', a * mt1 + b ).scatter('Midterm 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.with_column('Residual', mt2 - (a * mt1 + b)).scatter('Midterm 1', 'Residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.where(\"Midterm 1\", mt1_actual).hist('Midterm 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.where(\"Midterm 1\", are.between_or_equal_to(mt1_actual-2, mt1_actual+2)).hist('Midterm 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_mt2(mt1):\n",
    "    near = scores.where(\"Midterm 1\", are.between_or_equal_to(mt1-2, mt1+2))\n",
    "    return near.column(\"Midterm 2\").mean()\n",
    "\n",
    "avg_mt2(mt1_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt2_avg = scores.apply(avg_mt2, 'Midterm 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.drop(2).with_column('Avg', mt2_avg).scatter('Midterm 1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.scatter('Midterm 1', 'Midterm 2', group='Mentored')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.hist('Midterm 1', group='Mentored', bins=np.arange(0, 41, 5), normed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.hist('Midterm 2', group='Mentored', bins=np.arange(0, 51, 5), normed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_mentor = scores.where(\"Mentored\", False)\n",
    "\n",
    "def avg_mt2_no_mentor(mt1):\n",
    "    near = no_mentor.where(\"Midterm 1\", are.between_or_equal_to(mt1-2, mt1+2))\n",
    "    return near.column(\"Midterm 2\").mean()\n",
    "\n",
    "predicted_mt2 = scores.apply(avg_mt2_no_mentor, \"Midterm 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.drop(2).with_column('Predicted Mt2', predicted_mt2).scatter('Midterm 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = scores.with_column(\"Improvement\", scores.column('Midterm 2') - predicted_mt2)\n",
    "\n",
    "scores.hist(\"Improvement\", bins=np.arange(-30, 31, 5), group=\"Mentored\", unit=\"point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def of_at_least_5(values):\n",
    "    return sum(values >= 5) / len(values)\n",
    "\n",
    "scores.select('Mentored', 'Improvement').group('Mentored', of_at_least_5).set_format(1, PercentFormatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.group(\"Mentored\", np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_ci(observations):\n",
    "    means = []\n",
    "    for i in np.arange(2000):\n",
    "        means.append(observations.sample().column(\"Improvement\").mean())\n",
    "    lower, upper = percentile(2.5, means), percentile(97.5, means)\n",
    "    print(\"Mean improvement:\", observations.column(\"Improvement\").mean())\n",
    "    print(\"95% CI of mean improvement:\", lower, \"to\", upper)\n",
    "\n",
    "mentored = scores.where(\"Mentored\", True)\n",
    "mean_ci(mentored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ci(mentored.where(\"Midterm 1\", are.below(20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ci(mentored.where(\"Midterm 1\", are.between(20, 30)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ci(mentored.where(\"Midterm 1\", are.above_or_equal_to(30)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}